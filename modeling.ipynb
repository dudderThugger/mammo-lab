{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T13:25:57.225134Z",
     "start_time": "2024-05-12T13:25:48.786203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\" # Choose which GPUs by checking current use with nvidia-smi\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "## Keras library also provides ResNet101V2 and ResNet50V2. Import them and use it for other experiments. \n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "import time\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "# Check CUDA functionality, restart kernel to change GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"*************************************\")\n",
    "print(gpus)\n",
    "print(\"*************************************\")\n",
    "\n",
    "# Define function to preprocess images as required by ResNet\n",
    "def preprocess(images, labels):\n",
    "    return tf.keras.applications.resnet_v2.preprocess_input(images), labels\n",
    "\n",
    "\n",
    "#setup train, validation, and test folders\n",
    "traindir = './train_800_600_simple_comparison_birad'\n",
    "valdir = './val_800_600_simple_comparison_birad'\n",
    "testdir = './test_800_600_simple_comparison_birad'\n",
    "dirName = '800_600'\n",
    "\n",
    "\n",
    "buffersize = 3\n",
    "#im_dim = 512\n",
    "im_dim_x = 800\n",
    "im_dim_y = 600\n",
    "batchSizeIntInitial = 10 \n",
    "batchSizeInt = 6\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    traindir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valdir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    testdir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "\n",
    "test_ds = test.map(preprocess)\n",
    "train_ds = train.map(preprocess)\n",
    "val_ds = val.map(preprocess)\n",
    "train_ds = train_ds.prefetch(buffer_size=buffersize)\n",
    "val_ds = val_ds.prefetch(buffer_size=buffersize)\n",
    "\n",
    "\n",
    "## set up hyperparameters, such as epochs, learning rates, cutoffs.\n",
    "epochs = 20\n",
    "lr = 0.004\n",
    "cutoff=0.5\n",
    "start_time = time.time()\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope(): # the entire model needs to be compiled within the scope of the distribution strategy\n",
    "    cb1 = EarlyStopping(monitor='val_accuracy', patience=4) # define early stopping callback function\n",
    "    cb2 = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2, min_lr=0.00001) # define LR reduction callback function\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    metr = [metrics.BinaryAccuracy(name='accuracy', threshold=cutoff), metrics.AUC(name='auc'), metrics.Precision(name='precision'),\n",
    "                metrics.Recall(name='recall')]\n",
    "#                 tfa.metrics.F1Score(name='f1_score')]\n",
    "    ptmodel = ResNet50V2(include_top=False, weights='imagenet', classes=2, input_shape=(im_dim_x, im_dim_y, 3), pooling='avg') # compile resnet152v2 with imagenet weights\n",
    "    ptmodel.trainable = False # freeze layers\n",
    "    ptmodel.layers[-1].trainable == True\n",
    "\n",
    "    # un-freeze the BatchNorm layers\n",
    "    for layer in ptmodel.layers:\n",
    "        if \"BatchNormalization\" in layer.__class__.__name__:\n",
    "            layer.trainable = True\n",
    "\n",
    "    last_output = ptmodel.output\n",
    "    x = tf.keras.layers.Flatten()(last_output)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(0.15)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "#    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    # # x = tf.keras.layers.Dropout(0.5, seed=34)(x)\n",
    "    # x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(ptmodel.input, x)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='BinaryCrossentropy',\n",
    "                  metrics=metr)\n",
    "\n",
    "print(\"---time taken : %s seconds ---\" % (time.time() - start_time))\n",
    "# Train model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[cb1, cb2])\n",
    "print(\"---time taken : %s seconds ---\" % (time.time() - start_time))\n",
    "# Test model\n",
    "testloss, testaccuracy, testauc, precision, recall = model.evaluate(test_ds)\n",
    "print('Test accuracy :', testaccuracy)\n",
    "print('Test AUC :', testauc)\n",
    "\n",
    "F1 = 2*float(precision)*float(recall)/(float(precision) + float(recall))\n",
    "print('Test F1 :', F1)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "\n",
    "# Model path setup. \n",
    "if not os.path.exists(\"saved_model_resnet50_simple\"+dirName):\n",
    "    os.makedirs(\"saved_model_resnet50_simple\"+dirName+'/')\n",
    "    \n",
    "model.save('saved_model_resnet50_simple'+dirName+'/resnet152v2_1')\n",
    "predicted_probs = np.array([])\n",
    "true_classes =  np.array([])\n",
    "IterationChecker = 0\n",
    "for images, labels in test_ds:\n",
    "    if IterationChecker == 0:\n",
    "        predicted_probs = model(images)\n",
    "        true_classes = labels.numpy()\n",
    "\n",
    "    IterationChecker += 1\n",
    "\n",
    "    predicted_probs = np.concatenate([predicted_probs,\n",
    "                       model(images)])\n",
    "    true_classes = np.concatenate([true_classes, labels.numpy()])\n",
    "# Since they are sigmoid outputs, you need to transform them into classes with a threshold, i.e 0.5 here:\n",
    "predicted_classes = [1 * (x[0]>=cutoff) for x in predicted_probs]\n",
    "# confusion matrix etc:\n",
    "conf_matrix = tf.math.confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n",
    "predicted_probs=np.squeeze(predicted_probs)\n",
    "predicted_classes = np.array(predicted_classes)\n",
    "true_classes=np.squeeze(true_classes)\n",
    "summedResults = np.stack((predicted_probs,predicted_classes,true_classes), axis = 1)\n",
    "##Print out statistics which test files are correctly predicted or not. \n",
    "np.savetxt(\"Resnet50_simple_comp_EMBED.csv\", summedResults, delimiter=',', header=\"predicted_probabilty,predicted_classes,true_classes\", comments=\"\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
