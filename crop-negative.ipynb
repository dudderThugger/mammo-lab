{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "data_path = '/home/szelesteya/projects/EMBED_Open_Data/'\n",
    "image_root_path = '/media/szelesteya/F824D4D024D492CC/EMBED-images/'\n",
    "image_training_path = image_root_path + 'training/'\n",
    "image_negative_path = image_root_path + 'negative-full'\n",
    "image_positive_path = image_root_path + 'positive-full'\n",
    "tables_path = data_path + 'tables/'\n",
    "image_croped_neg_path = image_training_path + 'negative/' \n",
    "\n",
    "df_neg = pd.read_csv(data_path + 'negative_empirical_png.csv')\n",
    "\n",
    "fix_resolution = [3328,4096]\n",
    "crop_size = [224, 224]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "def get_size_of_image(image_array):\n",
    "    height = image_array.shape[0]\n",
    "    width = image_array.shape[1]\n",
    "    full_resolution = height * width\n",
    "    diameter = math.sqrt( height ** 2 + width ** 2)\n",
    "    dark_area = np.sum(image_array == 0)\n",
    "    return [f'{height} x {width}', [height, width], full_resolution, diameter, dark_area]\n",
    "\n",
    "def crop_black_part(image_array):\n",
    "    # Cropping every column that doesn't contain tissue\n",
    "    not_dark = np.where(image_array != 0, 1, 0)\n",
    "    tissue_distrib_x = np.sum(not_dark, axis=0) / not_dark.shape[0]\n",
    "    tissue_distri_y = np.sum(not_dark, axis=1) / not_dark.shape[1]\n",
    "    is_tissue_x = np.where(tissue_distrib_x > 0.1, 1, 0)\n",
    "    is_tissue_y = np.where(tissue_distri_y > 0.1, 1, 0)\n",
    "\n",
    "    first_tissue_x = np.where(is_tissue_x == 1)[0][0]\n",
    "    last_tissue_x = np.where(is_tissue_x == 1)[-1][-1]\n",
    "    first_tissue_y = np.where(is_tissue_y == 1)[0][0]\n",
    "    last_tissue_y = np.where(is_tissue_y == 1)[-1][-1]\n",
    "\n",
    "    return image_array[first_tissue_y:last_tissue_y,first_tissue_x:last_tissue_x]\n",
    "\n",
    "\n",
    "def generate_crop_path(index, roi_num):\n",
    "    return image_croped_pos_path + f\"{index}_{roi_num}_cropped\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "def crop_negative_array(image_array):\n",
    "    tissue_array = np.array(crop_black_part(image_array))\n",
    "    tissue_width = tissue_array.shape[1]\n",
    "    tissue_height = tissue_array.shape[0]\n",
    "    \n",
    "    if crop_size[1] > tissue_width + 1:\n",
    "        x_offset_1 = 0\n",
    "        x_offset_2 = 0\n",
    "    else:\n",
    "        x_offset_1 = random.randint(0, tissue_width - crop_size[1])\n",
    "        x_offset_2 = random.randint(0, tissue_width - crop_size[1])\n",
    "    \n",
    "    y_half_point = round((tissue_height - crop_size[0]) / 2)\n",
    "    y_offset_1 = random.randint(0, y_half_point)\n",
    "    y_offset_2 = random.randint(y_half_point, tissue_height - crop_size[0])\n",
    "    \n",
    "    crop_arrays = [tissue_array[y_offset_1:(y_offset_1 + crop_size[0]), x_offset_1:(x_offset_1 + crop_size[1])], tissue_array[y_offset_2:(y_offset_2 + crop_size[0]), x_offset_2:(x_offset_2 + crop_size[1])]]\n",
    "    \n",
    "    ret_arrays = []\n",
    "\n",
    "    for crop_array in crop_arrays:\n",
    "        tissue_dist = np.sum(np.where((crop_array / 255) > 0.05, 1, 0)) / (crop_size[0] * crop_size[1])\n",
    "        too_bright = np.sum(np.where((crop_array / 255) > 0.9, 1, 0) / (crop_size[0] * crop_size[1]))\n",
    "        print(too_bright)\n",
    "        if too_bright > 0.5:\n",
    "            print(f\"Too much bright area on picture\")  \n",
    "        elif (tissue_dist < 0.5):\n",
    "            print(f\"Too much dark area on picture try to flip the roi horizontally\")\n",
    "        else:\n",
    "            print(f\"Image will be croped brightness {too_bright}\")\n",
    "            ret_arrays.append(crop_array)\n",
    "        \n",
    "    return ret_arrays"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "def crop_negative(idx):\n",
    "    path = f\"{image_croped_neg_path}{idx}\"\n",
    "    image = Image.open(df_neg.loc[idx,'png_path'])\n",
    "    resize_image_array = np.array(image.resize(fix_resolution))\n",
    "    tissue_image_array = crop_black_part(resize_image_array)\n",
    "    crops = crop_negative_array(tissue_image_array)\n",
    "    for i,crop in enumerate(crops):\n",
    "        path_crop = f\"{path}_{i}.png\"\n",
    "        df_neg_train.loc[len(df_neg_train),:] = df_neg.loc[idx,:]\n",
    "        df_neg_train.loc[len(df_neg_train) - 1,'negative_index'] = idx\n",
    "        #df_neg_train.loc[len(df_neg_train)-1,:] = df_neg.loc[idx,:][['empi_anon','acc_anon','side','asses','age_at_study','calc_find','calc_distrib','other_find','num_find','view_pos','eth_desc','study_date_anon','diag_study_date','relative_dcm_path','spot_mag','diag_date_diff','png_path']]\n",
    "        df_neg_train.loc[len(df_neg_train)-1,'training_path'] = path_crop\n",
    "        print(f\"Saving image {path_crop}\")\n",
    "        im1 = Image.fromarray(crop, mode='L')\n",
    "        im1.save(path_crop, mode='L')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "crop_negative(df_neg.loc[50,:],50)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "df_neg_train = pd.DataFrame(columns=df_neg.columns).rename(columns={'Unnamed: 0': 'negative_index'})\n",
    "for i in range(0,250):\n",
    "    print(f\"Cropping image number {i} / {280}\")\n",
    "    crop_negative(i)\n",
    "\n",
    "df_neg_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "source": [
    "df_neg_train['label_0'] = 0\n",
    "df_neg_train = df_neg_train.rename(columns={'training_path':'crop_path'})\n",
    "df_neg_train['asses'] = 'N'\n",
    "\n",
    "with open('neg_training.csv','w') as f:\n",
    "    df_neg_train.to_csv(f)\n",
    "\n",
    "df_neg_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "source": [
    "df_neg_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
