{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8541e889-d330-43d0-93d2-28759ff78ff0",
   "metadata": {},
   "source": [
    "# Resizing images to fix sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50424e5c-9504-4df7-adb8-473c23e998dc",
   "metadata": {},
   "source": [
    "## Examining the size distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f5dfc8-171a-496d-a961-01baf987c886",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "data_path = '/home/szelesteya/projects/EMBED_Open_Data/'\n",
    "image_root_path = '/media/szelesteya/F824D4D024D492CC/EMBED-images/'\n",
    "image_training_path = image_root_path + 'training/'\n",
    "image_negative_path = image_root_path + 'negative-full'\n",
    "image_positive_path = image_root_path + 'positive-full'\n",
    "tables_path = data_path + 'tables/'\n",
    "\n",
    "df_pos = pd.read_csv(data_path + 'positive_empirical_png.csv')\n",
    "df_neg = pd.read_csv(data_path + 'negative_empirical_png.csv')\n",
    "\n",
    "fix_resolution = [4096, 3328]\n",
    "fix_crop_image = [700, 700]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6f0da555-143e-4a29-93f9-4550aa0b7a53",
   "metadata": {},
   "source": [
    "### Functions to extract information about the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43aece0-77c7-4071-a2ea-46841079fdd0",
   "metadata": {},
   "source": [
    "def parse_ROI(roi_coords_row):\n",
    "    roi_coords_array = roi_coords_row[2:-1].split('(')\n",
    "    roi_rects = []\n",
    "    \n",
    "    for i in range(len(roi_coords_array)):\n",
    "        roi_coords_str = roi_coords_array[i].split(')')[0].replace(\" \",\"\").split(',')\n",
    "        if \"\" not in roi_coords_str:\n",
    "            try:\n",
    "                roi_coords = [eval(j.replace('[', '').replace(']','')) for j in roi_coords_str]\n",
    "    \n",
    "                x_min = roi_coords[1]\n",
    "                y_min = roi_coords[0]\n",
    "                x_max = roi_coords[3]\n",
    "                y_max = roi_coords[2]\n",
    "                \n",
    "                roi_rects.append([x_min, y_min, x_max, y_max])\n",
    "            except SyntaxError:\n",
    "                print(roi_coords_str)\n",
    "\n",
    "    return roi_rects\n",
    "\n",
    "def get_sizes_of_ROI(roi_coords_array):\n",
    "    sizes = []\n",
    "\n",
    "    for roi in roi_coords_array:\n",
    "        size_str = f'{roi[2]-roi[0]} x {roi[3] - roi[1]}'\n",
    "        height = roi[2] - roi[0]\n",
    "        width = roi[3] - roi[1]\n",
    "        full_resolution = height * width\n",
    "        diameter = math.sqrt(height ** 2 + width ** 2)\n",
    "        sizes.append([size_str,[height, width], height * width, diameter])\n",
    "\n",
    "    return sizes\n",
    "\n",
    "def get_size_of_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_array = np.array(image)\n",
    "    height = image_array.shape[0]\n",
    "    width = image_array.shape[1]\n",
    "    full_resolution = height * width\n",
    "    diameter = math.sqrt( height ** 2 + width ** 2)\n",
    "    dark_area = np.sum(image_array == 0)\n",
    "    return [f'{height} x {width}', [height, width], full_resolution, diameter, dark_area]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ed71f036-3b71-4755-8fcf-0e3a9c474458",
   "metadata": {},
   "source": [
    "### Looping through the images and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f120a15a-2d47-4718-a22f-41f18a0ecb50",
   "metadata": {},
   "source": [
    "diameters_for_ROI = []\n",
    "diameters_for_image = []\n",
    "ratio_of_ROI = []\n",
    "ratio_of_dark = []\n",
    "\n",
    "for i in range(len(df_pos)):\n",
    "    if i % 10 == 0:\n",
    "        print(f'{i + 1}/{len(df_pos)}')\n",
    "    roi_coords_str = df_pos.loc[i,'ROI_coords']\n",
    "    png_image_path = df_pos.loc[i, 'png_path']\n",
    "    image_size = get_size_of_image(png_image_path)\n",
    "    roi_coords = get_sizes_of_ROI(parse_ROI(roi_coords_str))\n",
    "    \n",
    "    for sizes_tuple in roi_coords:\n",
    "        diameter = sizes_tuple[3]\n",
    "        diameters_for_ROI.append(diameter)\n",
    "\n",
    "for i in range(len(df_neg)):\n",
    "    if i % 10 == 0:\n",
    "        print(f'{i+1}/{len(df_neg)}')\n",
    "    png_image_path = df_neg.loc[i, 'png_path'] \n",
    "    image_size = get_size_of_image(png_image_path)\n",
    "    diameters_for_image.append(image_size[3])\n",
    "\n",
    "df_pos_img_sizes = pd.DataFrame([diameters_for_ROI, diameters_for_image, ratio_of_ROI, ratio_of_dark])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b4134392-698f-4d68-b4a4-7f47fecc9595",
   "metadata": {},
   "source": [
    "### Showcasing the extracted data on histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c583551-8a9c-41ed-b385-de4b5611ecfa",
   "metadata": {},
   "source": [
    "def show_roi_hist(roi_sizes_tuples, image_size_tuples=None):\n",
    "    ratios_of_ROI = []\n",
    "    diameters_of_ROI = []\n",
    "    \n",
    "    for i, row in enumerate(roi_sizes_tuples):\n",
    "        if image_size_tuples is not None: \n",
    "            image_size_tuple = eval(image_size_tuples[i])\n",
    "            image_size = image_size_tuple[2]\n",
    "        else:\n",
    "            image_size = fix_resolution[0] * fix_resolution[1]\n",
    "            \n",
    "        roi_size_tuples = eval(row)\n",
    "        ratios = []\n",
    "    \n",
    "        for roi_tuple in roi_size_tuples:\n",
    "            ratio = roi_tuple[2] / image_size \n",
    "            diameter = roi_tuple[3]\n",
    "            ratios.append(ratio)\n",
    "            ratios_of_ROI.append(ratio)\n",
    "            diameters_of_ROI.append(diameter)\n",
    "    \n",
    "        calc_findings.loc[i, 'ratios'] = str(ratios)\n",
    "\n",
    "    plt.hist(ratios_of_ROI)\n",
    "    plt.title('Ratios of each ROI bounding rectangle to the whole image')\n",
    "    plt.savefig('ratio_of_roi')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(diameters_of_ROI, bins = 30)\n",
    "    plt.title('Diameters of each bounding rectangle')\n",
    "    plt.savefig('diameter_of_roi')\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03da59f3-b228-4dba-9be4-1e28de2a36f4",
   "metadata": {},
   "source": [
    "plt.hist(diameters_for_ROI)\n",
    "plt.title('Diameters of bounding rectangles')\n",
    "plt.savefig('diameters_of_ROI')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(diameters_for_image)\n",
    "plt.title('Diameters of whole image')\n",
    "plt.savefig('diameters_of_image')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84a7830-af70-4a4c-857d-bb8338d4d885",
   "metadata": {},
   "source": [
    "show_roi_hist(calc_findings['roi_size_tuples'], calc_findings['image_size_tuple'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0ecf1a9e-1915-4117-9d6b-59a45796f2b2",
   "metadata": {},
   "source": [
    "### Calculate the ratio of height and wight then and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59c27e0e-ade6-4607-b8fc-06fa8d28bdcb",
   "metadata": {},
   "source": [
    "# Concatanating the positive and negative sets\n",
    "all_samples = pd.concat([negative_samples, calc_findings], axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d581e3ad-d7f8-440e-b3a5-14cd77624440",
   "metadata": {},
   "source": [
    "image_sizes_str = [ eval(tuple)[0] for tuple in all_sample['image_size_tuple'] ]\n",
    "sizes_counted = Counter(image_sizes_str)\n",
    "sizes = pd.Series(sizes_counted).reset_index()\n",
    "sizes.columns = ['Image Size', 'Frequency']\n",
    "\n",
    "resolutions = pd.Series(Counter([ round(eval(tuple)[1][0] / eval(tuple)[1][1], 3) for tuple in all_samples['image_size_tuple'] ])).reset_index()\n",
    "resolutions.columns = ['Resolution', 'Frequency']\n",
    "# print(resolutions)\n",
    "# sizes = sizes.merge(resolutions_counted, on='Frequency')\n",
    "\n",
    "plt.bar(sizes['Image Size'], sizes['Frequency'])\n",
    "for i, size in sizes.iterrows():\n",
    "    plt.text(i, size['Frequency'] + 1, str(size['Frequency']), ha='center', va='bottom')\n",
    "plt.title('Image Sizes')\n",
    "plt.xticks(rotation=70)\n",
    "plt.savefig('sizes')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar([str(res) for res in resolutions['Resolution']], resolutions['Frequency'])\n",
    "for i, resolution in resolutions.iterrows():\n",
    "    plt.text(i, resolution['Frequency'] + 1, str(resolution['Frequency'].astype(int)), ha='center', va='bottom')\n",
    "plt.title('Resolutions')\n",
    "plt.xticks(rotation=70)\n",
    "plt.savefig('resolutions')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "633f6b8c-9917-4bcb-99d8-856780734e15",
   "metadata": {},
   "source": [
    "### Agreeing at fixed resolution of 3328 * 4096 and resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc58726-0fd6-4892-98dd-d125efa4ca31",
   "metadata": {},
   "source": [
    "fix_resolution = [600, 800]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5aaa0ef-3724-433c-8766-63acecc66c65",
   "metadata": {},
   "source": [
    "def resize_calc(i):\n",
    "    image_path = image_resized_path + f'/{i}_pos.png'\n",
    "    \n",
    "    if not Path(image_path).exists():\n",
    "        df_row = calc_findings.loc[i]\n",
    "        png_path = df_row['full_png_path']\n",
    "        size_tuple = eval(df_row['image_size_tuple'])\n",
    "        original_size = size_tuple[1]\n",
    "        width_distortion = float(fix_resolution[0]) / float(original_size[0])\n",
    "        height_distortion = float(fix_resolution[1]) / float(original_size[1])\n",
    "        \n",
    "        roi_coords = parse_ROI(df_row['ROI_coords'])\n",
    "        resized_roi_coords = []\n",
    "    \n",
    "        for j, roi_coords in enumerate(roi_coords):\n",
    "            new_x_min = round(float(roi_coords[0]) * width_distortion)\n",
    "            new_x_max = round(float(roi_coords[2]) * width_distortion)\n",
    "            new_y_min = round(float(roi_coords[1]) * height_distortion)\n",
    "            new_y_max = round(float(roi_coords[3]) * height_distortion)\n",
    "    \n",
    "            resized_roi_coords.append([new_x_min, new_y_min, new_x_max, new_y_max])\n",
    "    \n",
    "        image = Image.open(png_path)\n",
    "        resized_image = image.resize(fix_resolution)\n",
    "        resized_image.save(image_path, 'PNG')\n",
    "    \n",
    "        calc_findings.loc[i,'resized_roi_coords'] = str(resized_roi_coords)\n",
    "        calc_findings.loc[i,'resized_roi_sizes'] = str(get_sizes_of_ROI(resized_roi_coords))\n",
    "        calc_findings.loc[i,'resized_path'] = image_path\n",
    "\n",
    "def resize_negative(i):\n",
    "    image_path = image_resized_path + f'/{i}_neg.png'\n",
    "    \n",
    "    if not Path(image_path).exists():\n",
    "        df_row = negative_samples.loc[i]\n",
    "        png_path = df_row['full_png_path']\n",
    "        size_tuple = eval(df_row['image_size_tuple'])\n",
    "        original_size = size_tuple[1]\n",
    "        wheightidth_distortion = float(fix_resolution[0]) / float(original_size[0])\n",
    "        width_distortion = float(fix_resolution[1]) / float(original_size[1])\n",
    "    \n",
    "        image = Image.open(png_path)\n",
    "        resized_image = image.resize(fix_resolution)\n",
    "        resized_image.save(image_path, 'PNG')\n",
    "        \n",
    "        negative_samples.loc[i,'resized_path'] = image_path    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dd7d806-fc0e-4c09-95c9-d08fd1e096c8",
   "metadata": {},
   "source": [
    "calc_length = len(calc_findings)\n",
    "negative_length = len(negative_samples)\n",
    "negative_samples.reset_index()\n",
    "\n",
    "for i in range(calc_length):\n",
    "    if i % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Resizing progression for calc_findings {i+1} / {calc_length}')\n",
    "        \n",
    "    resize_calc(i)\n",
    "\n",
    "# for i in range(negative_length):\n",
    "#     if i % 10 == 0:\n",
    "#         clear_output(wait=True)\n",
    "#         print(f'Resizing progression for negative pictures {i+1} / {negative_length}')\n",
    "        \n",
    "#     resize_negative(i)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print('Done')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "407ca981-f667-45b8-9857-d4cc57f66552",
   "metadata": {},
   "source": [
    "show_roi_hist(calc_findings['resized_roi_sizes'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61e6a513-c454-40c0-a529-b6386113c2a0",
   "metadata": {},
   "source": [
    "# Keep only empirical informations\n",
    "pos_empi =  calc_findings[['empi_anon',\n",
    "                           'acc_anon',\n",
    "                           'ImageLateralityFinal',\n",
    "                           'calcfind',\n",
    "                           'calcdistri',\n",
    "                           'age_at_study',\n",
    "                           'ETHNICITY_DESC',\n",
    "                           'resized_roi_coords',\n",
    "                           'resized_path',\n",
    "                           'path_severity']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8625b254-7c8b-46dc-baf8-8f41a13ed40d",
   "metadata": {},
   "source": [
    "# Dropping values so we only have 1 image per patient\n",
    "pos_empi_unique = pos_empi.sort_values(by=['age_at_study'],ascending=False).drop_duplicates(subset=['empi_anon'], keep='first').sample(frac=1).rename(columns={'ImageLateralityFinal':'side',\n",
    "                                                                                                                                                              'ETHNICITY_DESC':'eth_desc'})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b4826a80-860d-4ad9-8003-c45ab14c6e58",
   "metadata": {},
   "source": [
    "data = pd.read_csv(data_path + '/tables/EMBED_OpenData_clinical_reduced.csv')\n",
    "\n",
    "pos_empi_unique = pos_empi_unique.merge(data, how='left', on=['empi_anon', 'acc_anon', 'side', 'age_at_study'], validate='1:m')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b26d949d-765c-4e89-9c97-0a2d48fcae7d",
   "metadata": {},
   "source": [
    "pos_empi_unique = pos_empi_unique.sort_values(by=['study_date_anon'], ascending=False).drop_duplicates(subset=['empi_anon'], keep='first').sample(frac=1)\n",
    "\n",
    "pos_empi_unique_reduced = pos_empi_unique[['empi_anon',\n",
    "                                   'acc_anon',\n",
    "                                   'side',\n",
    "                                   'calcfind',\n",
    "                                   'calcdistri',\n",
    "                                   'asses',\n",
    "                                   'age_at_study',\n",
    "                                   'eth_desc',\n",
    "                                   'resized_roi_coords',\n",
    "                                   'resized_path']]\n",
    "\n",
    "with open(data_path + 'pos_empi_reduced.csv', 'w') as f:\n",
    "    pos_empi_unique_reduced.to_csv(f, index=False)    \n",
    "\n",
    "\n",
    "pos_empi_unique_reduced"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84408492-74ab-4f86-ba94-211350a3dffa",
   "metadata": {},
   "source": [
    "with open(data_path + 'empi_pos.csv', 'w') as f:\n",
    "    pos_empi_unique.to_csv(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "87517a0e-52b0-4c3e-888c-b7623822761c",
   "metadata": {},
   "source": [
    "### Cropping images with same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4249197-162f-4aad-ac3a-f4b78ee65298",
   "metadata": {},
   "source": [
    "croped_image_path = image_root_path + ''\n",
    "\n",
    "croped_image_size = [700,700]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac22b4f6-2b60-43cc-83b1-e4f77f2b56a8",
   "metadata": {},
   "source": [
    "def crop_positive_image(i):\n",
    "    calc_finding_row = calc_findings.loc[i]\n",
    "    image_array = np.array(Image.open(calc_finding_row['resized_path']))\n",
    "    roi_coords = eval(calc_finding_row['resized_roi_coords'])\n",
    "    croped_path_root = image_root_path + 'croped/'\n",
    "    crop_coords = []\n",
    "    crop_paths = []\n",
    "    \n",
    "    for j, roi_coord in enumerate(roi_coords):\n",
    "        x_min = roi_coord[0]\n",
    "        y_min = roi_coord[1]\n",
    "        x_max = roi_coord[2]\n",
    "        y_max = roi_coord[3]\n",
    "\n",
    "        x_center = round((x_min + x_max) / 2)\n",
    "        y_center = round((y_min + y_max) / 2)\n",
    "\n",
    "        croped_height = croped_image_size[0]\n",
    "        croped_width = croped_image_size[1]\n",
    "\n",
    "        x_offset = random.randint(-round(croped_width / 8), round(croped_width / 8))\n",
    "        y_offset = random.randint(-round(croped_height / 8), round(croped_height / 8))\n",
    "\n",
    "        x_crop = x_center - round(croped_width / 2) + x_offset\n",
    "        y_crop = y_center - round(croped_height / 2) + y_offset\n",
    "        \n",
    "        \n",
    "        if x_crop < 0:\n",
    "            x_crop = 0\n",
    "        elif x_crop + croped_width > fix_resolution[1]:\n",
    "            x_crop = fix_resolution[1] - croped_width - 1\n",
    "\n",
    "        if y_crop < 0:\n",
    "            y_crop = 0\n",
    "        elif y_crop + croped_height > fix_resolution[0]:\n",
    "            y_crop = fix_resolution[0] - croped_height - 1\n",
    "\n",
    "        crop_coords.append([y_crop, x_crop])\n",
    "        path = f'{croped_path_root}pos_{i}_{j}.png'\n",
    "        crop_paths.append(path)\n",
    "\n",
    "        roi_array = image_array[y_crop:(y_crop + croped_height),x_crop:(x_crop + croped_width)]\n",
    "        plt.imshow(roi_array, cmap='grey')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(path)\n",
    "\n",
    "\n",
    "    calc_findings.loc[i,'crop_coords'] = str(crop_coords)\n",
    "    calc_findings.loc[i,'crop_paths'] = str(crop_paths)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b6296b7-846d-48fc-8f1f-3b3304c4b0e9",
   "metadata": {},
   "source": [
    "def crop_negative_image(i):\n",
    "    negative_sample_row = negative_samples.loc[i]\n",
    "    # print(negative_sample_row['resized_path'])\n",
    "    image_array = np.array(Image.open(negative_sample_row['resized_path']))\n",
    "    croped_path_root = image_root_path + 'croped/'\n",
    "\n",
    "    crop_coords = []\n",
    "    crop_paths = []\n",
    "\n",
    "    croped_image_height = croped_image_size[0]\n",
    "    croped_image_width = croped_image_size[1]\n",
    "    try_treshold = 0\n",
    "    \n",
    "    # Cropping 2 pictures per screening\n",
    "    for j in range(2):        \n",
    "        crop_succesful = False\n",
    "        \n",
    "        while not crop_succesful:\n",
    "            # Generating random offset for the crop until the picture contains mostly tissues\n",
    "            x_offset = random.randint(0, fix_resolution[1] - croped_image_width - 1)\n",
    "            start_y = round(fix_resolution[0] / 2) * (j)\n",
    "            end_y = round(fix_resolution[0] / 2) * (j + 1) - croped_image_height - 1\n",
    "            y_offset = random.randint(start_y, end_y)\n",
    "\n",
    "            crop_array = image_array[y_offset:croped_image_height,x_offset:croped_image_width]\n",
    "            crop_tissue = crop_array[crop_array > 0]\n",
    "            tissue_percentage = (np.sum(crop_tissue) / (croped_image_width * croped_image_height)) * 100\n",
    "\n",
    "            if tissue_percentage > 10:\n",
    "                crop_succesful = True\n",
    "                crop_coords.append([y_offset, x_offset])\n",
    "                \n",
    "                # Get image array of croping\n",
    "                crop = image_array[y_offset:(y_offset + croped_image_height),x_offset:(x_offset + croped_image_width)]\n",
    "                print([y_offset, x_offset])\n",
    "\n",
    "                path = f'{croped_path_root}neg_{i}_{j}.png'\n",
    "                crop_paths.append(path)\n",
    "                plt.imshow(crop, cmap='grey')\n",
    "                plt.axis('off')\n",
    "                plt.savefig(path)\n",
    "                plt.show()\n",
    "                \n",
    "                continue\n",
    "                \n",
    "            if try_treshold > 10:\n",
    "                crop_succesful = True\n",
    "                print(f'{start_y} {end_y} {y_offset}')\n",
    "                continue\n",
    "            try_treshold += 1\n",
    "\n",
    "    negative_samples.loc[i, 'crop_coords'] = str(crop_coords)\n",
    "    negative_samples.loc[i, 'crop_paths'] = str(crop_paths)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ee47777-d478-488c-b0e2-91c49bba7ce5",
   "metadata": {},
   "source": [
    "crop_negative_image(1893)\n",
    "#print(negative_samples.loc[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5980116-0b83-4745-9c6e-6f9ee99d5b09",
   "metadata": {},
   "source": [
    "print(( 4096 * 3328) / (700 * 700))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e72fb3a8-9a74-45fd-b57d-10082602a2ad",
   "metadata": {},
   "source": [
    "## Saving modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d224f-97a6-4652-b172-eb04def42b4b",
   "metadata": {},
   "source": [
    "all_samples = pd.concat([negative_sample, calc_findings], axis=0)\n",
    "\n",
    "with open(data_path + 'calc_findings_full.csv', 'w') as f:\n",
    "    calc_findings.to_csv(f)\n",
    "\n",
    "with open(data_path + 'negative_full.csv', 'w') as f:\n",
    "    negative_sample.to_csv(f)\n",
    "\n",
    "with open(data_path + 'all_sample_full.csv', 'w') as f:\n",
    "    all_sample.to_csv(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f99e0-40a2-449d-b3c4-3a31cb7a5243",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0328fb-3358-4346-aa58-1f5316956f13",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef092296-138b-4ec4-85ad-27836feae8de",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f320b-e6df-4ca5-8651-d45579925b87",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e63bc-f844-45cd-a63a-d3cb4488688f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b911e9-b002-42e3-8dae-3f4a931f8c2b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1a9e4-7798-4c22-bdbc-d9c6d8ca15a6",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
