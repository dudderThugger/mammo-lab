{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T11:46:24.511276Z",
     "start_time": "2024-05-26T11:46:08.351137Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Choose which GPUs by checking current use with nvidia-smi\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import metrics\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Check CUDA functionality, restart kernel to change GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"*************************************\")\n",
    "print(gpus)\n",
    "print(\"*************************************\")\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "# Define function to preprocess images as required by ResNet\n",
    "def preprocess(images, labels):\n",
    "    return tf.keras.applications.resnet_v2.preprocess_input(images), labels\n",
    "\n",
    "\n",
    "# setup train, validation, and test folders\n",
    "traindir = '/mnt/d/datasets/INBREAST/split/train'\n",
    "valdir = '/mnt/d/datasets/INBREAST/split/validation'\n",
    "testdir = '/mnt/d/datasets/INBREAST/split/test'\n",
    "dirName = '2_classes'\n",
    "\n",
    "buffersize = 2\n",
    "# im_dim = 512\n",
    "im_dim_x = 224\n",
    "im_dim_y = 224\n",
    "batchSizeIntInitial = 10\n",
    "batchSizeInt = 6\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    traindir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valdir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    testdir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "\n",
    "test_ds = test.map(preprocess)\n",
    "train_ds = train.map(preprocess)\n",
    "val_ds = val.map(preprocess)\n",
    "train_ds = train_ds.prefetch(buffer_size=buffersize)\n",
    "val_ds = val_ds.prefetch(buffer_size=buffersize)\n",
    "\n",
    "## set up hyperparameters, such as epochs, learning rates, cutoffs.\n",
    "epochs = 30\n",
    "lr = 0.004\n",
    "cutoff = 0.5\n",
    "start_time = time.time()\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():  # the entire model needs to be compiled within the scope of the distribution strategy\n",
    "    # cb1 = EarlyStopping(monitor='val_accuracy', patience=4)  # define early stopping callback function\n",
    "    cb1 = ModelCheckpoint(\"/mnt/d/datasets/INBREAST/results/resnet50.h5\", monitor=\"val_accuracy\", verbose=2, save_best_only=True, mode=\"max\")\n",
    "    # cb2 = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2,\n",
    "    #                         min_lr=0.00001)  # define LR reduction callback function\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    metr = [metrics.BinaryAccuracy(name='accuracy', threshold=cutoff), metrics.AUC(name='auc'),\n",
    "            metrics.Precision(name='precision'),\n",
    "            metrics.Recall(name='recall')]\n",
    "    #                 tfa.metrics.F1Score(name='f1_score')]\n",
    "    ptmodel = ResNet50V2(include_top=False, weights='imagenet', classes=2, input_shape=(im_dim_x, im_dim_y, 3),\n",
    "                         pooling='avg')  # compile resnet152v2 with imagenet weights\n",
    "    ptmodel.trainable = False  # freeze layers\n",
    "    ptmodel.layers[-1].trainable = True\n",
    "\n",
    "\n",
    "    # un-freeze the BatchNorm layers\n",
    "    # for layer in ptmodel.layers:\n",
    "    #     if \"BatchNormalization\" in layer.__class__.__name__:\n",
    "    #         layer.trainable = False # ??\n",
    "\n",
    "    last_output = ptmodel.output\n",
    "    x = tf.keras.layers.Flatten()(last_output)\n",
    "    # x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "    # #     x = tf.keras.layers.Dropout(0.15)(x)\n",
    "    # x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    # #    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    # # x = tf.keras.layers.Dropout(0.5, seed=34)(x)\n",
    "    # x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(ptmodel.input, x)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='BinaryCrossentropy',\n",
    "                  metrics=metr)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:46:08.571313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 13:46:10.004062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/dudder/miniconda3/envs/tf/lib/\n",
      "2024-05-26 13:46:10.005652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/dudder/miniconda3/envs/tf/lib/\n",
      "2024-05-26 13:46:10.005677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-05-26 13:46:11.840896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:11.859449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:11.859723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "*************************************\n",
      "Found 3936 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:46:18.608417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 13:46:18.611700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:18.612187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:18.612529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:19.633632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:19.633985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:19.634008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-26 13:46:19.634255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-26 13:46:19.634306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2731 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 492 files belonging to 2 classes.\n",
      "Found 492 files belonging to 2 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T09:58:40.181943Z",
     "start_time": "2024-05-26T09:43:51.398294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"---time taken : %s seconds ---\" % (time.time() - start_time))\n",
    "# Train model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[cb1])\n",
    "print(\"---time taken : %s seconds ---\" % (time.time() - start_time))"
   ],
   "id": "24bf22b106b42927",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---time taken : 75.09799408912659 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 11:43:51.444826: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 3936\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 11:43:59.953587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-05-26 11:44:00.458423: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-05-26 11:44:02.013183: W tensorflow/tsl/framework/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-05-26 11:44:02.324167: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1b368870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-26 11:44:02.324264: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "2024-05-26 11:44:02.429835: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-26 11:44:03.012564: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-05-26 11:44:03.060745: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-05-26 11:44:03.144224: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-05-26 11:44:03.422456: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-05-26 11:44:03.554756: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-05-26 11:44:03.791726: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-05-26 11:44:03.952163: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.7630 - auc: 0.8429 - precision: 0.8464 - recall: 0.7099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 11:44:55.891713: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 492\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79065, saving model to /mnt/d/datasets/INBREAST/results/resnet50.h5\n",
      "656/656 [==============================] - 128s 176ms/step - loss: 0.4727 - accuracy: 0.7630 - auc: 0.8429 - precision: 0.8464 - recall: 0.7099 - val_loss: 0.4196 - val_accuracy: 0.7907 - val_auc: 0.8815 - val_precision: 0.8492 - val_recall: 0.7670\n",
      "Epoch 2/100\n",
      "656/656 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8079 - auc: 0.8930 - precision: 0.8853 - recall: 0.7589\n",
      "Epoch 2: val_accuracy improved from 0.79065 to 0.79472, saving model to /mnt/d/datasets/INBREAST/results/resnet50.h5\n",
      "656/656 [==============================] - 136s 200ms/step - loss: 0.3846 - accuracy: 0.8079 - auc: 0.8930 - precision: 0.8853 - recall: 0.7589 - val_loss: 0.3884 - val_accuracy: 0.7947 - val_auc: 0.8986 - val_precision: 0.8560 - val_recall: 0.7670\n",
      "Epoch 3/100\n",
      "656/656 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8267 - auc: 0.9097 - precision: 0.8955 - recall: 0.7854\n",
      "Epoch 3: val_accuracy did not improve from 0.79472\n",
      "656/656 [==============================] - 445s 679ms/step - loss: 0.3594 - accuracy: 0.8267 - auc: 0.9097 - precision: 0.8955 - recall: 0.7854 - val_loss: 0.3962 - val_accuracy: 0.7785 - val_auc: 0.8969 - val_precision: 0.7796 - val_recall: 0.8495\n",
      "Epoch 4/100\n",
      "280/656 [===========>..................] - ETA: 3:45 - loss: 0.3428 - accuracy: 0.8375 - auc: 0.9207 - precision: 0.8891 - recall: 0.8131"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m---time taken : \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m seconds ---\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time))\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcb1\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m---time taken : \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m seconds ---\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time))\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m--> 133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\u001B[38;5;241m.\u001B[39m_call_flat(\n\u001B[1;32m    135\u001B[0m     filtered_flat_args, captured_inputs\u001B[38;5;241m=\u001B[39mconcrete_function\u001B[38;5;241m.\u001B[39mcaptured_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:336\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m    331\u001B[0m captures \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_captures_container\u001B[38;5;241m.\u001B[39mget_snapshot()\n\u001B[1;32m    333\u001B[0m \u001B[38;5;66;03m# cache_key_deletion_observer is useless here. It's based on all captures.\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;66;03m# A new cache key will be built later when saving ConcreteFunction because\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \u001B[38;5;66;03m# only active captures should be saved.\u001B[39;00m\n\u001B[0;32m--> 336\u001B[0m lookup_func_key, _ \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_cache_key\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mcaptures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mlookup(lookup_func_key, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m concrete_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py:140\u001B[0m, in \u001B[0;36mmake_cache_key\u001B[0;34m(args, captures)\u001B[0m\n\u001B[1;32m    135\u001B[0m captures_dict_tracetype \u001B[38;5;241m=\u001B[39m trace_type\u001B[38;5;241m.\u001B[39mfrom_value(\n\u001B[1;32m    136\u001B[0m     captures, signature_context)\n\u001B[1;32m    138\u001B[0m \u001B[38;5;66;03m# TODO(fmuham): Use the actual FunctionType\u001B[39;00m\n\u001B[1;32m    139\u001B[0m dummy_function_type \u001B[38;5;241m=\u001B[39m function_type\u001B[38;5;241m.\u001B[39mFunctionType([\n\u001B[0;32m--> 140\u001B[0m     \u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mParameter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43margs_kwargs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mParameter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPOSITIONAL_ONLY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m                            \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m                            \u001B[49m\u001B[43margs_signature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m ], collections\u001B[38;5;241m.\u001B[39mOrderedDict(captures_dict_tracetype\u001B[38;5;241m.\u001B[39mmapping))\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function_cache\u001B[38;5;241m.\u001B[39mFunctionCacheKey(\n\u001B[1;32m    147\u001B[0m     dummy_function_type,\n\u001B[1;32m    148\u001B[0m     make_function_context()), signature_context\u001B[38;5;241m.\u001B[39mdeletion_observer\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:47\u001B[0m, in \u001B[0;36mParameter.__init__\u001B[0;34m(self, name, kind, optional, type_constraint)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(type_constraint, (trace\u001B[38;5;241m.\u001B[39mTraceType, \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m))):\n\u001B[1;32m     43\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     44\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mType constraints can only be an instance of a TraceType but got \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[1;32m     45\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype_constraint=\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(type_constraint) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m for Parameter \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name)\n\u001B[0;32m---> 47\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     48\u001B[0m     name,\n\u001B[1;32m     49\u001B[0m     kind,\n\u001B[1;32m     50\u001B[0m     default\u001B[38;5;241m=\u001B[39mCAPTURED_DEFAULT_VALUE \u001B[38;5;28;01mif\u001B[39;00m optional \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mempty,\n\u001B[1;32m     51\u001B[0m     annotation\u001B[38;5;241m=\u001B[39mtype_constraint\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m type_constraint \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mempty)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test model\n",
    "# Loading checkpoint model\n",
    "model.load_weights(\"/mnt/d/datasets/INBREAST/results/resnet50.h5\")\n",
    "testloss, testaccuracy, testauc, precision, recall = model.evaluate(test_ds)\n",
    "print('Test accuracy :', testaccuracy)\n",
    "print('Test AUC :', testauc)\n",
    "\n",
    "F1 = 2 * float(precision) * float(recall) / (float(precision) + float(recall))\n",
    "print('Test F1 :', F1)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "\n",
    "# Model path setup.\n",
    "if not os.path.exists(\"saved_model_resnet50_simple\" + dirName):\n",
    "    os.makedirs(\"saved_model_resnet50_simple\" + dirName + '/')\n",
    "\n",
    "model.save('saved_model_resnet50_simple' + dirName + '/resnet152v2_1')\n",
    "predicted_probs = np.array([])\n",
    "true_classes = np.array([])\n",
    "IterationChecker = 0\n",
    "for images, labels in test_ds:\n",
    "    if IterationChecker == 0:\n",
    "        predicted_probs = model(images)\n",
    "        true_classes = labels.numpy()\n",
    "\n",
    "    IterationChecker += 1\n",
    "\n",
    "    predicted_probs = np.concatenate([predicted_probs,\n",
    "                                      model(images)])\n",
    "    true_classes = np.concatenate([true_classes, labels.numpy()])\n",
    "# Since they are sigmoid outputs, you need to transform them into classes with a threshold, i.e 0.5 here:\n",
    "predicted_classes = [1 * (x[0] >= cutoff) for x in predicted_probs]\n",
    "# confusion matrix etc:\n",
    "conf_matrix = tf.math.confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n",
    "predicted_probs = np.squeeze(predicted_probs)\n",
    "predicted_classes = np.array(predicted_classes)\n",
    "true_classes = np.squeeze(true_classes)\n",
    "summedResults = np.stack((predicted_probs, predicted_classes, true_classes), axis=1)\n",
    "##Print out statistics which test files are correctly predicted or not.\n",
    "np.savetxt(\"Resnet50_simple_comp_EMBED.csv\", summedResults, delimiter=',',\n",
    "           header=\"predicted_probabilty,predicted_classes,true_classes\", comments=\"\")"
   ],
   "id": "ee5b1596be02907f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
